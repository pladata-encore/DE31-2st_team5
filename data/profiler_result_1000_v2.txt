Wrote profile results to tfidf.py.lprof
Timer unit: 1e-06 s

Total time: 0.047052 s
File: tfidf.py
Function: generate_doc at line 15

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    15                                           @profile
    16                                           def generate_doc(file_path, text_column):
    17         4         87.1     21.8      0.2      with open(file_path, 'r', encoding='utf-8') as csv_file:
    18         2         25.1     12.5      0.1          csv_reader = csv.DictReader(csv_file)
    19      2002      46152.1     23.1     98.1          for row in csv_reader:
    20      2000        787.7      0.4      1.7              yield row[text_column]

Total time: 9.69874 s
File: tfidf.py
Function: preprocessing at line 22

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    22                                           @profile
    23                                           def preprocessing(documents):
    24         1       1721.5   1721.5      0.0      stop_words = set(stopwords.words("english"))
    25         1          1.8      1.8      0.0      wordnet_lemmatizer = WordNetLemmatizer()
    26                                               
    27      1001      36604.8     36.6      0.4      for text in documents:
    28      1000       3988.7      4.0      0.0          text = str(text).lower()
    29      1000    2490890.8   2490.9     25.7          tokens = word_tokenize(text)
    30      1000      71967.2     72.0      0.7          tokens = [i.replace(",", "") for i in tokens]
    31      1000     858046.7    858.0      8.8          tokens = [num2words(i) if i.isdigit() else i for i in tokens]
    32      1000       8315.2      8.3      0.1          adj_text = " ".join(tokens)
    33      1000      18583.4     18.6      0.2          adj_text = re.sub(r'^[^a-z]', ' ', adj_text)
    34      1000    2324445.2   2324.4     24.0          tokens = word_tokenize(adj_text)
    35      1000      58426.2     58.4      0.6          tokensWSW = [word for word in tokens if word not in stop_words]
    36      1000    3819963.1   3820.0     39.4          lemmatized_list = [wordnet_lemmatizer.lemmatize(word) for word in tokensWSW]
    37      1000       5542.3      5.5      0.1          clean_text = " ".join(lemmatized_list)
    38      1000        246.4      0.2      0.0          yield clean_text

Total time: 10.0675 s
File: tfidf.py
Function: calculate_tfidf at line 40

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    40                                           @profile
    41                                           def calculate_tfidf(documents_generator):
    42         1         24.3     24.3      0.0      vectorizer = TfidfVectorizer()
    43         1   10067518.3    1e+07    100.0      tfidf_matrix = vectorizer.fit_transform(documents_generator).toarray()
    44         1          0.3      0.3      0.0      return tfidf_matrix

Total time: 0.575261 s
File: tfidf.py
Function: calculate_cosine_similarity at line 46

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    46                                           @profile
    47                                           def calculate_cosine_similarity(tfidf_matrix):
    48                                               # 코사인 유사도 계산
    49         1     575260.1 575260.1    100.0      similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)
    50         1          0.7      0.7      0.0      return similarity_matrix

Total time: 0.217837 s
File: tfidf.py
Function: clustering_model at line 52

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    52                                           @profile
    53                                           def clustering_model(similarity_matrix):
    54                                               # 계층적 병합 클러스터링 수행
    55         1     217836.4 217836.4    100.0      clustering = linkage(similarity_matrix, method='ward')
    56         1          0.3      0.3      0.0      return clustering

Total time: 1.73376 s
File: tfidf.py
Function: plot_dendrogram at line 58

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    58                                           @profile
    59                                           def plot_dendrogram(clustering, labels):
    60         1       2460.5   2460.5      0.1      plt.figure(figsize=(10, 7))
    61         1    1730843.8    2e+06     99.8      dendrogram(clustering, labels=labels, orientation='right')
    62         1        119.8    119.8      0.0      plt.xlabel('Distance')
    63         1         53.2     53.2      0.0      plt.ylabel('Document')
    64         1        245.8    245.8      0.0      plt.title('Hierarchical Clustering Dendrogram')
    65         1         35.9     35.9      0.0      plt.show()

Total time: 12.614 s
File: tfidf.py
Function: main at line 67

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    67                                           @profile
    68                                           def main(file_path):
    69         1          0.8      0.8      0.0      file_path = "aticle_sample.csv"
    70         1          0.2      0.2      0.0      text_column = "context"
    71                                           
    72         1      18801.7  18801.7      0.1      num_documents = sum(1 for _ in generate_doc(file_path, text_column))
    73                                           
    74         1        288.0    288.0      0.0      document_labels = ['Document{}'.format(i) for i in range(1, num_documents + 1)]
    75                                           
    76         1          1.4      1.4      0.0      documents_generator = generate_doc(file_path, text_column)
    77         1          0.9      0.9      0.0      preprocessing_documents =  preprocessing(documents_generator)
    78         1   10067961.2    1e+07     79.8      tfidf_matrix = calculate_tfidf(preprocessing_documents)
    79         1     575290.2 575290.2      4.6      similarity_matrix = calculate_cosine_similarity(tfidf_matrix)
    80         1     217860.4 217860.4      1.7      clustering = clustering_model(similarity_matrix)
    81         1    1733789.4    2e+06     13.7      plot_dendrogram(clustering, labels = document_labels)

